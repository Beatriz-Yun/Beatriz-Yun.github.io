---
layout: post
title: "[논문] 100 Must-Read NLP Papers"
date: 2021-11-07 20:11
image: books.jpg
tags:
categories: papers 100_Must-Read_NLP_Papers
---

### [100 Must-Read NLP Papers](http://masatohagiwara.net/100-nlp-papers/)

#### Machine Learning

- Avrim Blum and Tom Mitchell: Combining Labeled and Unlabeled Data with Co-Training, 1998.
  - [paper](https://www.cs.cmu.edu/~avrim/Papers/cotrain.pdf)
- John Lafferty, Andrew McCallum, Fernando C.N. Pereira: Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data, ICML 2001.
  - [paper](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)
- Charles Sutton, Andrew McCallum. An Introduction to Conditional Random Fields for Relational Learning.
  - [paper](https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf)
- Kamal Nigam, et al.: Text Classification from Labeled and Unlabeled Documents using EM. Machine Learning, 1999.
  - [paper](https://www.ri.cmu.edu/pub_files/pub1/nigam_k_1999_1/nigam_k_1999_1.pdf)
- Kevin Knight: Bayesian Inference with Tears, 2009.
  - [paper](https://www.socsci.uci.edu/~lpearl/courses/readings/Knight2009_BayesWithTears.pdf)
- Marco Tulio Ribeiro et al.: “Why Should I Trust You?”: Explaining the Predictions of Any Classifier, KDD 2016.
  - [paper](https://arxiv.org/abs/1602.04938)
- Marco Tulio Ribeiro et al.: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList, ACL 2020.
  - [paper](https://arxiv.org/abs/2005.04118)


#### Neural Models
- Richard Socher, et al.: Dynamic Pooling and Unfolding Recursive Autoencoders for Paraphrase Detection, NIPS 2011.
  - [paper](https://proceedings.neurips.cc/paper/2011/file/3335881e06d4d23091389226225e17c7-Paper.pdf)
- Ronan Collobert et al.: Natural Language Processing (almost) from Scratch, J. of Machine Learning Research, 2011.
  - [paper](https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf)
- Richard Socher, et al.: Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank, EMNLP 2013.
  - [paper](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)
- Xiang Zhang, Junbo Zhao, and Yann LeCun: Character-level Convolutional Networks for Text Classification, NIPS 2015.
  - [paper](https://arxiv.org/abs/1509.01626)
- Yoon Kim: Convolutional Neural Networks for Sentence Classification, 2014.
  - [paper](https://arxiv.org/abs/1408.5882)
- Christopher Olah: Understanding LSTM Networks, 2015.
  - [paper](https://web.stanford.edu/class/cs379c/archive/2018/class_messages_listing/content/Artificial_Neural_Network_Technology_Tutorials/OlahLSTM-NEURAL-NETWORK-TUTORIAL-15.pdf)
- Matthew E. Peters, et al.: Deep contextualized word representations, 2018.
  - [paper](https://arxiv.org/abs/1802.05365)
- Jacob Devlin, et al.: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, 2018.
  - [paper](https://arxiv.org/abs/1810.04805)
- Yihan Liu et al. RoBERTa: A Robustly Optimized BERT Pretraining Approach, 2020.
  - [paper](https://arxiv.org/abs/1907.11692)



#### Clustering & Word/Sentence Embeddings

- Peter F Brown, et al.: Class-Based n-gram Models of Natural Language, 1992.
  - [paper](https://www.cs.cmu.edu/~roni/11761/PreviousYearsHandouts/classlm.pdf)
- Tomas Mikolov, et al.: Efficient Estimation of Word Representations in Vector Space, 2013.
  - [paper](https://arxiv.org/abs/1301.3781)
- Tomas Mikolov, et al.: Distributed Representations of Words and Phrases and their Compositionality, NIPS 2013.
  - [paper](https://papers.nips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)
- Quoc V. Le and Tomas Mikolov: Distributed Representations of Sentences and Documents, 2014.
  - [paper](https://arxiv.org/abs/1405.4053)
- Jeffrey Pennington, et al.: GloVe: Global Vectors for Word Representation, 2014.
  - [paper](https://nlp.stanford.edu/pubs/glove.pdf)
- Ryan Kiros, et al.: Skip-Thought Vectors, 2015.
  - [paper](https://arxiv.org/abs/1506.06726)
- Piotr Bojanowski, et al.: Enriching Word Vectors with Subword Information, 2017.
  - [paper](https://arxiv.org/abs/1607.04606)
- Daniel Cer et al.: Universal Sentence Encoder, 2018.
  - [paper](https://arxiv.org/abs/1803.11175)



#### Topic Models

- Thomas Hofmann: Probabilistic Latent Semantic Indexing, SIGIR 1999.
  - [paper](https://sigir.org/wp-content/uploads/2017/06/p211.pdf)
- David Blei, Andrew Y. Ng, and Michael I. Jordan: Latent Dirichlet Allocation, J. Machine Learning Research, 2003.
  - [paper](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)


#### Language Modeling
- Joshua Goodman: A bit of progress in language modeling, MSR Technical Report, 2001.
  - [paper](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.59.8929&rep=rep1&type=pdf)
- Stanley F. Chen and Joshua Goodman: An Empirical Study of Smoothing Techniques for Language Modeling, ACL 2006.
  - [paper](https://dash.harvard.edu/bitstream/handle/1/25104739/tr-10-98.pdf)
- Yee Whye Teh: A Hierarchical Bayesian Language Model based on Pitman-Yor Processes, COLING/ACL 2006.
  - [paper](https://www.gatsby.ucl.ac.uk/~ywteh/research/compling/acl2006.pdf)
- Yee Whye Teh: A Bayesian interpretation of Interpolated Kneser-Ney, 2006.
  - [paper](https://www.stats.ox.ac.uk/~teh/research/compling/hpylm.pdf)
- Yoshua Bengio, et al.: A Neural Probabilistic Language Model, J. of Machine Learning Research, 2003.
  - [paper](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- Andrej Karpathy: The Unreasonable Effectiveness of Recurrent Neural Networks, 2015.
 - [paper](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- Yoon Kim, et al.: Character-Aware Neural Language Models, 2015.
  - [paper](https://arxiv.org/abs/1508.06615)
- Alec Radford, et al.: Language Models are Unsupervised Multitask Learners, 2018.
  - [paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)


#### Segmentation, Tagging, Parsing

- Donald Hindle and Mats Rooth. Structural Ambiguity and Lexical Relations, Computational Linguistics, 1993.
  - [paper](https://aclanthology.org/J93-1005.pdf)
- Adwait Ratnaparkhi: A Maximum Entropy Model for Part-Of-Speech Tagging, EMNLP 1996.
  - [paper](https://aclanthology.org/W96-0213.pdf)
- Eugene Charniak: A Maximum-Entropy-Inspired Parser, NAACL 2000.
  - [paper](https://aclanthology.org/A00-2018.pdf)
- Michael Collins: Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms, EMNLP 2002.
  - [paper](https://aclanthology.org/W02-1001.pdf)
- Dan Klein and Christopher Manning: Accurate Unlexicalized Parsing, ACL 2003.
  - [paper](https://aclanthology.org/P03-1054.pdf)
- Dan Klein and Christopher Manning: Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency, ACL 2004.
  - [paper](https://aclanthology.org/P04-1061.pdf)
- Joakim Nivre and Mario Scholz: Deterministic Dependency Parsing of English Text, COLING 2004.
  - [paper](https://aclanthology.org/C04-1010.pdf)
- Ryan McDonald et al.: Non-Projective Dependency Parsing using Spanning-Tree Algorithms, EMNLP 2005.
  - [paper](https://aclanthology.org/H05-1066.pdf)
- Daniel Andor et al.: Globally Normalized Transition-Based Neural Networks, 2016.
  - [paper](https://www.seas.upenn.edu/~strctlrn/bib/PDF/nonprojectiveHLT-EMNLP2005.pdf)
- Oriol Vinyals, et al.: Grammar as a Foreign Language, 2015.
  - [paper](https://arxiv.org/abs/1412.7449)


#### Sequential Labeling & Information Extraction

- Marti A. Hearst: Automatic Acquisition of Hyponyms from Large Text Corpora, COLING 1992.
  - [paper](https://aclanthology.org/C92-2082.pdf)
- Collins and Singer: Unsupervised Models for Named Entity Classification, EMNLP 1999.
  - [paper](https://aclanthology.org/W99-0613.pdf)
- Patrick Pantel and Dekang Lin, Discovering Word Senses from Text, SIGKDD, 2002.
  - [paper](https://www.patrickpantel.com/download/papers/2002/kdd02.pdf)
- Mike Mintz et al.: Distant supervision for relation extraction without labeled data, ACL 2009.

- Zhiheng Huang et al.: Bidirectional LSTM-CRF Models for Sequence Tagging, 2015.

- Xuezhe Ma and Eduard Hovy: End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF, ACL 2016.


#### Machine Translation & Transliteration, Sequence-to-Sequence Models

- Peter F. Brown et al.: A Statistical Approach to Machine Translation, Computational Linguistics, 1990.

- Kevin Knight, Graehl Jonathan. Machine Transliteration. Computational Linguistics, 1992.

- Dekai Wu: Inversion Transduction Grammars and the Bilingual Parsing of Parallel Corpora, Computational Linguistics, 1997.

- Kevin Knight: A Statistical MT Tutorial Workbook, 1999.

- Kishore Papineni, et al.: BLEU: a Method for Automatic Evaluation of Machine Translation, ACL 2002.

- Philipp Koehn, Franz J Och, and Daniel Marcu: Statistical Phrase-Based Translation, NAACL 2003.

- Philip Resnik and Noah A. Smith: The Web as a Parallel Corpus, Computational Linguistics, 2003.

- Franz J Och and Hermann Ney: The Alignment-Template Approach to Statistical Machine Translation, Computational Linguistics, 2004.

- David Chiang. A Hierarchical Phrase-Based Model for Statistical Machine Translation, ACL 2005.

- Ilya Sutskever, Oriol Vinyals, and Quoc V. Le: Sequence to Sequence Learning with Neural Networks, NIPS 2014.

- Oriol Vinyals, Quoc Le: A Neural Conversation Model, 2015.

- Dzmitry Bahdanau, et al.: Neural Machine Translation by Jointly Learning to Align and Translate, 2014.

- Minh-Thang Luong, et al.: Effective Approaches to Attention-based Neural Machine Translation, 2015.

- Rico Sennrich et al.: Neural Machine Translation of Rare Words with Subword Units. ACL 2016.

- Yonghui Wu, et al.: Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, 2016.

- Melvin Johnson, et al.: Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation, 2016.

- Jonas Gehring, et al.: Convolutional Sequence to Sequence Learning, 2017.

- Ashish Vaswani, et al.: Attention Is All You Need, 2017.


#### Coreference Resolution

- Vincent Ng: Supervised Noun Phrase Coreference Research: The First Fifteen Years, ACL 2010.

- Kenton Lee at al.: End-to-end Neural Coreference Resolution, EMNLP 2017.



#### Automatic Text Summarization

- Kevin Knight and Daniel Marcu: Summarization beyond sentence extraction. Artificial Intelligence 139, 2002.

- James Clarke and Mirella Lapata: Modeling Compression with Discourse Constraints. EMNLP-CONLL 2007.

- Ryan McDonald: A Study of Global Inference Algorithms in Multi-Document Summarization, ECIR 2007.

- Wen-tau Yih et al.: Multi-Document Summarization by Maximizing Informative Content-Words. IJCAI 2007.

- Alexander M Rush, et al.: A Neural Attention Model for Sentence Summarization. EMNLP 2015.

- Abigail See et al.: Get To The Point: Summarization with Pointer-Generator Networks. ACL 2017.




#### Question Answering and Machine Comprehension

- Pranav Rajpurkar et al.: SQuAD: 100,000+ Questions for Machine Comprehension of Text. EMNLP 2015.

- Minjoon Soo et al.: Bi-Directional Attention Flow for Machine Comprehension. ICLR 2015.



#### Generation, Reinforcement Learning

- Jiwei Li, et al.: Deep Reinforcement Learning for Dialogue Generation, EMNLP 2016.

- Marc’Aurelio Ranzato et al.: Sequence Level Training with Recurrent Neural Networks. ICLR 2016.

- Samuel R Bowman et al.: Generating sentences from a continuous space, CoNLL 2016.

- Lantao Yu, et al.: SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient, AAAI 2017.
